{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 19:43:22.748490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-23 19:43:24.223777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import History\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,242\n",
      "Trainable params: 431,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 19:49:11.820449: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout_7/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.4589 - sparse_categorical_accuracy: 0.8324 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 2/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.3224 - sparse_categorical_accuracy: 0.8825 - val_loss: 0.2777 - val_sparse_categorical_accuracy: 0.8986\n",
      "Epoch 3/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.2787 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2689 - val_sparse_categorical_accuracy: 0.9024\n",
      "Epoch 4/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.2492 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.2626 - val_sparse_categorical_accuracy: 0.9034\n",
      "Epoch 5/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.9169 - val_loss: 0.2614 - val_sparse_categorical_accuracy: 0.9056\n",
      "Epoch 6/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.2016 - sparse_categorical_accuracy: 0.9248 - val_loss: 0.2581 - val_sparse_categorical_accuracy: 0.9108\n",
      "Epoch 7/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.2424 - val_sparse_categorical_accuracy: 0.9152\n",
      "Epoch 8/40\n",
      "1572/1572 [==============================] - 11s 7ms/step - loss: 0.1715 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9100\n",
      "Epoch 9/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9400 - val_loss: 0.2825 - val_sparse_categorical_accuracy: 0.9008\n",
      "Epoch 10/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.2676 - val_sparse_categorical_accuracy: 0.9180\n",
      "Epoch 11/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.2808 - val_sparse_categorical_accuracy: 0.9172\n",
      "Epoch 12/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1289 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.2851 - val_sparse_categorical_accuracy: 0.9146\n",
      "Epoch 13/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.9114\n",
      "Epoch 14/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.1189 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.2915 - val_sparse_categorical_accuracy: 0.9124\n",
      "Epoch 15/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.9148\n",
      "Epoch 16/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.3327 - val_sparse_categorical_accuracy: 0.9158\n",
      "Epoch 17/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.1000 - sparse_categorical_accuracy: 0.9620 - val_loss: 0.3367 - val_sparse_categorical_accuracy: 0.9150\n",
      "Epoch 18/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.3249 - val_sparse_categorical_accuracy: 0.9128\n",
      "Epoch 19/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.3559 - val_sparse_categorical_accuracy: 0.9096\n",
      "Epoch 20/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.3413 - val_sparse_categorical_accuracy: 0.9142\n",
      "Epoch 21/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.3449 - val_sparse_categorical_accuracy: 0.9162\n",
      "Epoch 22/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.3569 - val_sparse_categorical_accuracy: 0.9150\n",
      "Epoch 23/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.9110\n",
      "Epoch 24/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.3614 - val_sparse_categorical_accuracy: 0.9134\n",
      "Epoch 25/40\n",
      "1572/1572 [==============================] - 9s 5ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.3818 - val_sparse_categorical_accuracy: 0.9108\n",
      "Epoch 26/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.4187 - val_sparse_categorical_accuracy: 0.9126\n",
      "Epoch 27/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3700 - val_sparse_categorical_accuracy: 0.9186\n",
      "Epoch 28/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.9094\n",
      "Epoch 29/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9724 - val_loss: 0.3694 - val_sparse_categorical_accuracy: 0.9122\n",
      "Epoch 30/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0713 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.9146\n",
      "Epoch 31/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.4636 - val_sparse_categorical_accuracy: 0.9166\n",
      "Epoch 32/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.4662 - val_sparse_categorical_accuracy: 0.9166\n",
      "Epoch 33/40\n",
      "1572/1572 [==============================] - 10s 6ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.4119 - val_sparse_categorical_accuracy: 0.9166\n",
      "Epoch 34/40\n",
      "1572/1572 [==============================] - 10s 7ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.4464 - val_sparse_categorical_accuracy: 0.9154\n",
      "Epoch 35/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.9172\n",
      "Epoch 36/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.9148\n",
      "Epoch 37/40\n",
      "1572/1572 [==============================] - 9s 6ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.9146\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5068 - sparse_categorical_accuracy: 0.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5068017244338989, 0.9071000218391418]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_conv_2 = History()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(patience=30,monitor=\"val_loss\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"sparse_categorical_accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=35, validation_data=(X_valid, y_valid) ,callbacks=[early_stopping, history_conv_2])\n",
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
